<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
<title>Justin Meiners</title>
<description>Welcome to my personal site about programming, mathematics, and philosophy!</description>
<link>https://justinmeiners.github.io</link>
<lastBuildDate>Sun, 22 Dec 2019 15:56:57 -0700</lastBuildDate>
<item>
<pubDate>Wed, 18 Dec 2019 15:56:57 -0700</pubDate>
<title>Shamans: A 3D Turn-based Strategy Game for iPad</title>
<guid isPermaLink="true">https://justinmeiners.github.io/shamans/</guid>
</item>
<item>
<pubDate>Sun, 28 Jul 2019 15:56:57 -0600</pubDate>
<title>Write Your Own Proof-of-Work Blockchain</title>
<guid isPermaLink="true">https://justinmeiners.github.io/tiny-blockchain/</guid>
</item>
<item>
<pubDate>Sat, 29 Jun 2019 15:56:57 -0600</pubDate>
<title>text2image</title>
<guid isPermaLink="true">https://github.com/justinmeiners/text2image</guid>
</item>
<item>
<pubDate>Sat, 08 Jun 2019 15:56:57 -0600</pubDate>
<title>Think in Math. Write in Code.</title>
<guid isPermaLink="true">https://justinmeiners.github.io/think-in-math/</guid>
<description><![CDATA[ 
 Think in Math. Write in Code.
-----------------------------
**6/8/19**

Programmers love to discuss programming languages.
Besides debating their own merits, we integrate them into our identities and even infer things about others who use them.
Some even defend a form of [Linguistic Determinism][6] that thinking is limited to what is typable.

Since we spend so much time using languages, an interest in making them better is justified.
However, the character of these debates suggests that we think of them as something more.
Perhaps we have forgotten their primary role.
Programming languages are *implementation tools*, not *thinking tools*.
They are strict formal languages invented to instruct machines in a human-friendly way.
In contrast, thoughts are best expressed through a medium which is free and flexible.

## Thinking in Math

The natural language which has been effectively used for thinking about computation, for thousands of years, is mathematics.
Most people don't think of math as free or flexible.
Their experience of seeing scary symbols and memorizing steps in school is quite the opposite.
I hope readers of this article have had a better experience with math, such as in a [discrete math][1] or linear algebra course;
the kind that involves constructing clear definitions and deductions, and is written in prose with a mix of symbols (most symbols weren't even invented until the [16th century][7]).

Math allows you to reason about logical structures, free from other constraints.
This is also what programming requires: creating logical systems to solve problems.
Take a look at the basic pattern for programming:

1. Identify a problem
2. Design algorithms and data structures to solve it
3. Implement and test them

In practice, work is not so well organized as there is interplay between steps.
You may write code to inform the design.
Even so, the basic pattern is followed over and over.

Notice that steps 1 and 2 are the ones that take most of our time, ability, and effort.
At the same time, these steps don't lend themselves to programming languages.
That doesn't stop programmers from attempting to solve them in their editor, but they end up with code that is muddled, slow, or that solves the wrong problem.
It's not that programming languages aren't good enough yet.
It's that *no formal language* could be good at it.
Our brains just don't think that way.
When problems get hard, we draw diagrams and discuss them with collaborators.

Ideally, steps 1 and 2 are solved first, and only then will a programming language be used to solve step 3.
This has an added benefit of transforming the implementation process.
With a mathematical solution in hand, you can then focus on choosing the best representation and implementation, and writing better code, knowing what the end goal will be.

## Implementation Concerns

Why are programming languages burdensome thinking tools?
One reason is that writing code is inseparably connected with implementation.
Implementation concerns are necessary for instructing computers and are worth doing well, but they also distract from the problem to be solved.
Think about all the considerations for writing a simple function:

- What inputs should I provide?
- What should they be named?
- What types should they be? (Even dynamically typed languages must consider types, it's just implicit.)
- Should I pass them by value or by reference?
- What file should I put the function in?
- Should the result be reused, or is it fast enough to recalculate it every time?

The list can go on. The point is that these considerations have nothing to do with what the function does.
They distract from the problem the function is trying to solve.

Many languages aim to hide details such as these, which is helpful, especially for mundane tasks.
However, they cannot transcend their role as an implementation tool.
SQL is easily one of the most successful examples of this, but it is ultimately concerned with implementation concerns such as tables, rows, indices, and types.
Because of this, programmers still design complicated queries in informal terms, like what they want to "get," before writing a bunch of `JOIN`s.

## Inflexible Abstractions

Another limitation of programming languages is that they are poor abstraction tools.
Typically, when we discuss abstraction in engineering, we mean hiding implementation details.
A complex operation or process is packaged into a "black box" with its contents hidden and well-defined inputs and outputs exposed.
Accompanying the box is a fictional story about what it does, that is easy to understand.

![black box picture](black-box.gif)

Black boxes are essential for engineering large systems since the details are too overwhelming to hold in your head.
They also have many well-known limitations.
A black box [leaks][5] because its brief description cannot completely determine its behavior.
The opaque interfaces introduce [inefficiencies][8], like duplication and fragmented design.

Most importantly for problem-solving, black boxes are rigid.
They present a fixed level of abstraction which may be too high-level or too low-level for the problem.
In theory, you can always look inside the box, but in code, the abstraction level at any one time is fixed.
They also offer only one perspective of abstraction.
A high-level web server may provide a terrific interface for serving JSON, but be useless if one wants an interface for serving incomplete data streams, such as output from a program.

In contrast, the word abstraction in math is nothing like hiding information.
Here, abstraction means extracting the essential features or characteristics of something, in relation to a particular context.
Unlike black boxes, no information is hidden.
They don't leak in the same way.
You are encouraged to adjust to the right level of abstraction and quickly jump between perspectives:

- Is this problem best represented as a table? Or, a function?
- Can I look at the whole system as a function?
- Can I treat this collection of things as a single unit?
- Should I look at the whole system or a single part?
- What assumptions should I make? Should I make them stronger or weaker?

Just look at the many ways of looking at a function:

[![function representations](functions.gif)][10]

Major branches of math represent commonly useful abstractions:

- Geometry abstracts fundamental shapes from objects in the world (or [transformation invariants][9], depending on how cosmic you want to get).
- Topology abstracts surface features from their shapes.
- Group theory abstracts binary operations to properties about how they are composed and inverted.

However, these fields aren't the limit.
You can pick the properties that are important to the problem and ignore everything else.
The example project at the end shows how this is done.

Programming languages are great for building black boxes; they provide functions, classes, and modules, all of which help wrap up code into nice interfaces.
However, when trying to solve problems and design solutions, what you actually want is the math kind of abstraction.
If you try to think at the keyboard, the black boxes available to you will warp your view.

## Problem Representation

Just as programming languages are limited in their ability to abstract, they also are limited in how they represent data.
The very act of implementing an algorithm or data structure is picking *just one* of the many possible ways to represent it.
Typically, this is not a decision you want to make until you understand what is needed.

For example, graphs (sets of vertices and edges) appear in many programming problems such as internet networks, pathfinding, and social networks.
Despite their simple definition, choosing how to represent them is hard and depends on their use case:

![math graph](graph.gif)

- The one which most closely matches the definition:  
  `vertices: vector<NodeData> edges: vector<pair<Int, Int>>`
  The vertices can be removed if you only care about connectivity.

- If you want to traverse a node's neighbors quickly, then you probably want a node structure:  
  `Node { id: Int, neighbors: vector<Node*> }`

- You could use an [adjacency matrix][11]. Where each row stores the neighbors of a particular node:  
  `connectivity: vector<vector<int>>`

- Pathfinding algorithms often work on graphs implicitly from a board of cells:  
  `walls: vector<vector<bool>>`

- In a peer-to-peer network, each computer is a vertex and each socket is an edge.
  The entire graph isn't even accessible from one machine! 

Math allows you to reason about the graph itself, solve the problem, and then choose an appropriate representation.
If you think in a programming language, you cannot delay this decision as your first line of code commits to a particular representation.

Note that the graph representations are too diverse to conform to a single interface, typeclass, or even program.
So creating a completely reusable library is impractical.
It can only work on a few types, or force all graphs into an inappropriate representation.
That doesn't mean libraries aren't useful.
Similar representations are needed again and again (like `std::vector`),
but you cannot write a library which solves a graph problem once and for all.

Some modern programming languages attempt to provide more mathematical abstraction tools.
For example, Haskell has `Ring` and `Group` typeclasses.
However, the representation issues show that these features must be less useful than their theoretical inspirations.
It is smart to write an algorithm which relies only on the associative property and document it is as such.
This is thinking in the language of math.
But, in practice, it can only reasonably work on a small family of similar types.
A simple generic with a few types in mind is appropriate.

As a corollary, programming languages should focus primarily on being useful implementation tools, rather than thinking tools.
C got this right in a big way.
Modern language features such as C#'s async and await provide great improvements for implementing concurrent programs.

## Example Project

So what does thinking in math look like?
Recently, I worked on an API at work for pricing cryptocurrency for merchants.
It takes into account recent price changes and recommends that merchants charge a higher price during volatile times.

Although we did some homework on the theory, we wanted to empirically test it to see how it performed during various market conditions.
To do so, I designed a bot to simulate a merchant doing business with our API, to see how it performs.

**BTC/USD (1 day)**

![btc usd](btc-usd.gif)

### Preliminaries

**Definition:** The **exchange rate** `r(t)` is the market rate of `fiat/crypto`.

**Definition:** The **merchant rate** `r'(t)` is the modified exchange rate which the merchant is advised to charge customers.

**Definition:** When a customer buys an item, we call that event a **purchase**.
A purchase consists of the price in fiat and a time. `p = (f, t)`.

**Theorem:** The amount of crypto for a purchase is found by applying the modified exchange rate
`t(p) = p(1) / r'(p(2))`.

**Proof:** `p(1) / r'(p(2)) = fiat / (fiat/crypto) = fiat * crypto/fiat = crypto`

**Definition:** When the merchant sells their crypto holdings, we call that event a **sale**.
A sale consists of an amount in crypto and a timestamp. `s = (c, t)`.

**Theorem:** The amount of fiat the merchant obtained from a sale is found by applying the exchange rate to the sale `g(s) = s(1) * r(s(2))`.

**Proof:** `s(1) * r(s(2)) = crypto * (fiat/crypto) = fiat`

**Definition:** The **balance** of a set of purchases and sales is the difference between all purchase crypto amounts and all sale crypto amounts.
 `b(P, S) = sum from i to N of t(p_i) - sum from j to M of s_j(1)`

Note that `b(P, S) >= 0` must always hold.

**Definition:** The **earnings** of a set of purchases and sales is the difference between sale fiat amounts and purchase fiat amounts.
`e(P, S) = sum from j to M of g(s_j(1)) - sum from i to N of p_i(1) >= 0`.

### Objective

**Definition:** We say that the merchant rate is **favorable** iff the earnings are non-negative for *most* sets of *typical* purchases and sales.
`r'(t) is favorable iff e(P, S) >= 0 `.

In a favorable case, the merchant didn't lose any fiat by accepting crypto.

*most* and *typical* will not be rigorously defined.

As part of *typical*, we can assume that merchants will sell their crypto in a timely manner.
So assume `s_i(2) - s_j(2) < W` for `i,j in {1.. M}` for some bound `W`.
Purchase amounts should be randomly distributed within a reasonable range that commerce is done. Perhaps $10-100.

**The goal of the bot is to verify that `r'(t)` is favorable.**

Note that this definition is only one measure of quality.
Perhaps protecting against the worst case is more important than being favorable.
In that case, we would be concerned about the ability to construct a set of purchases with very negative earnings.

### Algorithm

Repeat many times:

 1. Randomly choose a time range `[t0, t1]`.
 2. Generate a set of **purchases** at random times within `[t0, t1]`.
    The price should fall within a range `[p0, p1`] of *typical* prices.

 3. Generate a set of **sales** at evenly spaced times (perhaps with slight random noise) within `[t0, t1]`.
    Each sale should be for the full **balance** at that time.
 4. Calculate the **earnings** for these sets.
 5. Record the earnings.

After:

 1. Report how many earnings were negative and non-negative. Show a percentage for each.
 2. Identify the minimum and maximum earnings and report them.

### Conclusion

As you read this example, I think your tendency may be to think that its statements are obvious.
Certainly, none of these steps are hard.
However, it was surprising to me how many of my assumptions were corrected and how difficult it was to choose an objective definition of a **favorable** outcome.
This process helped me become aware of assumptions I would not have even considered if I had started by simply writing code.
Perhaps the greatest benefit was that after writing it, I was able to quickly review it with a co-worker and make corrections which were easy on paper, but would have been difficult to change in code.

I hope that thinking in the language of math will bring similar benefits to your projects!
Note that this example is only one style of utilizing mathematical thinking.
I recommend reading others by [Leslie Lamport][2], [Udi Manber][3], and [Alex Stepanov][4].

[1]: https://www.amazon.com/Introduction-Graph-Theory-Dover-Mathematics/dp/0486678709
[2]: https://lamport.azurewebsites.net/pubs/pubs.html#eatcs
[3]: https://www.amazon.com/Introduction-Algorithms-Creative-Udi-Manber/dp/0201120372
[4]: http://stepanovpapers.com/PAM.pdf
[5]: https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/
[6]: https://en.wikipedia.org/wiki/Linguistic_determinism
[7]: https://en.wikipedia.org/wiki/History_of_mathematical_notation#Symbolic_stage
[8]: https://www.youtube.com/watch?v=lHLpKzUxjGk
[9]: https://en.wikipedia.org/wiki/Felix_Klein#Erlangen_program
[10]: https://www.youtube.com/watch?v=ACZDnF8-9Ks
[11]: https://en.wikipedia.org/wiki/Adjacency_matrix 
 ]]></description>
</item>
<item>
<pubDate>Sun, 12 May 2019 15:56:57 -0600</pubDate>
<title>Notes On Vector Libraries</title>
<guid isPermaLink="true">https://justinmeiners.github.io/vector-libs/</guid>
<description><![CDATA[ 
 Notes on Vector Libraries
=========================

**05/12/2019**

A good vector math library is essential for graphics
and simulation programming.
However, implementing one that is flexible, efficient,
and easy to use is difficult.
Due to so many choices, experienced
programmers tend to write their own to accommodate their preference.

In this article I will survey a few of the most popular techniques and offer some design advice.
I will specifically focus on math theory and C implementations.

## Math

Before diving into the code.
It's helpful to review some of the math
to understand what we are aiming for. One thing to watch for
is operations that can be defined in terms of each other.
Rarely do I see libraries take advantage of this.

**Vector Operations**

On vectors in `R^N`

- addition `v + w` 
- subtraction `v - w`. Defined by addition: `a - b = a + (-b)`
- multiplication `v * w`
- scaling `a * v`
- normalization. Defined by length and scaling: `1/|v| * v`
    
From `R^N -> R`

- dot product `<v, w>`
- length `|v|`. Defined by dot product `sqrt(<v,v>)`
- angle. Defined by dot product and length `acos(<a,b>/|a||b|)`

Only on specific dimension, such as `R^2` or `R^3`

- cross product `a X b`
- angle (in the plane)

**Matrix Operations**

On all matrices `M(n x m)`

- addition `A + B`
- subtraction `A - B`
  Defined by addition `A - B = A + (-B)`
- scaling `bA`
- multiplication `AB`

On square matrices `M(n x n)`

- determinant `det(A)`
- inverse `A^-1`

Between vectors and matrices

- multiplication `Av`

Most programs use 2, 3, and 4
element vectors, and only a few operations
are specific to a given dimension.
So a lot of code can be condensed by writing algorithms
on N dimensional vectors.

Matrix operations are also very general.
But a few should be kept to a specific 
dimension (usually 3x3 or 4x4).
You do not want to implement a
general inverse or determinant function.

## 1. Simple Structs

    typedef struct
    {
        float x, y, z;
    } vec3;

    vec3 vec3_add(vec3 a, b)
    {
        vec3 r;
        r.x = a.x + b.x;
        r.y = a.y + b.y;
        r.z = a.z + b.z;
        return r;  
    }

This works well for smaller programs.
The best part is that expressions look nice (`a + 2.0*(b-d)`):

    vec3_add(a, vec3_scale(2.0, vec_sub(b, c)));

But, we have to copy this definition for every dimension.
We also have to avoid any algorithms that use
index or iteration.
Matrix vector multiplication gets ugly.

If you only have a few functions that need
indexing and you can index into a pointer to the first member:

    vec3 a;
    float* v = &a.x;
    v[0];

**Examples**

- [vec math](https://github.com/justinmeiners/pre-rendered-backgrounds/blob/master/source/engine/core/vec_math.h)

- [stb vec](https://github.com/nothings/obbg/blob/master/src/stb_vec.h)

## 2. Arrays

For `N` dimensional vectors
we might try to write functions which
operate on arrays of floats.
This is nice because it does not 
introduce another data structure, so 
other functions and vector libraries play nice with each other.

Unfortunately, C does not allow you to return
an array from the stack. You can only return a pointer
which must point to some valid region.
So either we do something horrible like `malloc` in each operation,
or pass in arrays for the return value.
Passing in arrays works, but it destroys the ability
to comfortably write simple expressions such as `a + 2.0*(b-d)`:

    void vecn_add(int n, float* a, float* b, float* ret);

    // intermediate results everywhere
    float temp[3];
    vecn_sub(3, b, d, temp);

    float temp2[3];
    vecn_scale(3, 2.0, temp, temp2);

    float final[3];
    vecn_add(3, a, temp2, final);

Plain arrays may be appropriate for matrices since they are not typically
involved in complex expressions. 
Matrices and large vectors, which would be inefficient to copy around
would also be a good use case.

Depending on the application you may not want
to sacrifice performance by introducing loops and branching
into every operation. As long as the dimensions
are input as a literals or macros, the small loops
should be unrolled at compile time.

**Examples:**

- [Accelerate](https://developer.apple.com/documentation/accelerate/vdsp)
- [linmath](https://github.com/datenwolf/linmath.h)

## 3. Struct + Union

A workaround to return an array from a function is to include it in a struct.
The tradeoff is that the size must be fixed and element access is a bit
uglier as it requires at least an extra letter.

    typedef struct
    {
        float e[3];
    } vec3;

    vec3 v;
    v.e[0] = 1;

The access syntax can be cleaned up with a union
but, [anonymous structs/unions](https://gcc.gnu.org/onlinedocs/gcc/Unnamed-Fields.html)
are a GCC extension and are non-standard.

    typedef union
    {
        float v[3];
        struct
        {
            float x;
            float y;
            float z; 
        }; 
    } vec3;

This gives you safe iterative access and nice named members,
but it is hard to combine with generic functions.
Either you use functions which operate on the internal arrays
and deal with the intermediate results.
Or, define fixed dimension functions which wrap
the generic ones:

    vec3 vec3_add(vec3 a, vec3 b);
    {
        vec3 temp;
        vecn_add(3, a.v, b.v, temp.v);
        return temp;
    }

I don't love this option.
If I need to write wrapper functions I might as well go back to method 1
and copy implementations around.

**Examples:**

- [Math 3D](https://github.com/arkanis/single-header-file-c-libs/blob/master/math_3d.h) (See Matrices)

## 4. Macros

Some clever macros can help you get the best of both worlds, and
parameterize the scalar types. This can be combined with 
an array or union data structure.
But, writing multi-line macros isn't very fun.

    #define DEFINE_VEC(T, N, SUF) \
    \
    void vec##N####SUF##_add(const T *a, const T *b,  T *r) \
    { \
        for (int i = 0; i < N; ++i) \
            r[i] = a[i] + b[i]; \
    } \

Then define the types you need:

    DEFINE_VEC(float, 2, f);
    DEFINE_VEC(float, 3, f);
    DEFINE_VEC(float, 4, f);

Usage:

    vec3f_add(a, b);

Functions which only apply to a specific dimension
can be defined outside of the macro:

    void vec3f_cross(const float* a, const float* b, float* r)
    {
        // ...
    }

**Examples:**

- [linmath](https://github.com/datenwolf/linmath.h)

## Closing Thoughts

In typical C fashion, I believe it is misguided to try to write
the *one true* vector library to serve all purposes.
These libraries are bloated and must choose tradeoffs which
don't fit your use case. Instead use the examples
above to write to tailor make vector functions as needed.

For further reading, see [On Vector Math Libraries](http://www.reedbeta.com/blog/2013/12/28/on-vector-math-libraries/).
It focuses on C++ and has a few other handy tips.
You can also read a [discussion](https://github.com/arkanis/single-header-file-c-libs/issues/3)
which led to these notes. 
 ]]></description>
</item>
<item>
<pubDate>Sun, 14 Apr 2019 15:56:57 -0600</pubDate>
<title>Foundations of Math Reading List</title>
<guid isPermaLink="true">https://justinmeiners.github.io/foundations-of-math-reading/</guid>
<description><![CDATA[ 
 Foundation of Math Reading List
-------------------------------

**04/13/2019**

One of my favorite courses in college was
philosophy of language.
Along with interesting philosphy
it introduced me to the foundations of math project
which has since become one of my 
favorite subjects to learn about.

Some of my favorite books of all time come out of this interest.
I wanted to organize a few of these
into a list for others who are interested in the topic.
Note that many good books were left out in favor of the very best.

You will notice a theme in my commentary.
The books I like most are those that don't
shy away from hard technical knowledge, but also
explore the philosophical ideas behind them.

The list is arranged in a progressive sequence
that will help prepare you for the next one.

### Logicomix

By: [Apostolos Doxiadis][l1]

![logicomix](logicomix.jpg)

Logicomix is actually a comic book! 
It tells an engaging historical narrative about the search for the foundations of math
and the birth of analytic philosophy, in the early 20th century. 

It introduces you to all the major characters
such as Gödel, Russel, Frege, and Wittgenstein and 
motivates the kinds of problems they were trying to solve.
The book also explores how these ideas connect to modern computer science.

It is an absolute joy to read and will give you a taste
of whether this is an interesting subject for you.

[l1]: https://www.apostolosdoxiadis.com

### Gödel, Escher, Bach

By: [Douglas Hofstadter][geb-1]

![godel escher bach](geb.jpg)

You probably have seen this work recommended elsewhere. 
Gödel, Escher, Bach really deserves all the praise that it gets.

Hofstadter covers an enormous range of topics
including formal systems, Godel's proof, theory of computation,
programming, molecular biology, and artificial intelligence.
Every topic is presented beautifully and with a lot of philosophical discussion.
In many ways it is an introduction to the big ideas in modern science.
It is written for a general audience and assumes no mathematical background.

[geb-1]: https://en.wikipedia.org/wiki/Douglas_Hofstadter

### Gödel's Proof.

By: [James Newman][gp-1] & [Ernest Nagel][gp-2]

![godel's proof](godels_proof.jpg)

Gödel, Escher, Bach does a good job of introducing the incompleteness theorem
and discussing its ramifications, but if you are like me you probably still won't
completely understand it after a first reading.

This concise book offers another perspective and a clear explanation
of the mathematics of the proof, its general strategy, and the
historical context surrounding the incompleteness problem.

[gp-1]: https://en.wikipedia.org/wiki/Ernest_Nagel)
[gp-2]: https://en.wikipedia.org/wiki/James_R._Newman

### Descartes Dream

By: [Phillip Davis][dd-1] & [Reuben Hersch][dd-2]

![descartes dream](descartes_dream.jpg)

In the 17th century Descartes had a dream in which he saw
a future world driven by mathematical calculations and logical systems.
The theme of this book is how this dream has become a reality.

The book explores how mathematics and computer science work together,
surveys several interesting fields, and examines ethical issues in the technological world.
This book is not technical, and should be appropriate for anyone interested in science
or technology.

If you like this book, the authors wrote another called *The Mathematical Experience*
which is focused more on pure mathematics.

[dd-1]: https://en.wikipedia.org/wiki/Philip_J._Davis
[dd-2]: https://en.wikipedia.org/wiki/Reuben_Hersh

### Computation: Finite & Infinite

By: [Marvin Minsky][mm-1]

![computation finite & infinite](computation.jpg)

Marvin Minsky is an incredibly clear and deep writer.
In this work he provides a mathematical framework
for thinking about mechanical machines and develops the 
theory of computation.

This book teaches you all you need to know about Turing machines, finite state, and neural networks.
My project: [McCulloch & Pitts Neural Net Simulator][mm-2]
is based on this book.

To read this book, you should understand some logic and basic set theory
such as that taught in an introductory proofs course.

Unfortunately, it is out of print and may be difficult to obtain (for a reasonable
amount of money).
I read it from my university's library. If that is not an option, I recommend you *find it online*.
If anyone knows of a place where I can reasonably purchase this book, let me know.

[mm-1]: https://en.wikipedia.org/wiki/Marvin_Minsky
[mm-2]: https://justinmeiners.github.io/neural-nets-sim/

### Structure and Interpretation of Computer Programs

By: [Gerald Sussman][sicp-4] & [Hal Abelson][sicp-5]

![sicp](sicp.jpg)

[Read Online][sicp-1]

This classic text is designed to teach programming to MIT students
who have some technical background in another areas of math and science.
It is a hard read, but it assumes no programming knowledge and teaches Scheme (a Lisp dialect) and
its full inter-workings from the ground up.

If you want to be a professional programmer,
this may be the only book you need to study.
What other book teaches you to write a symbolic differentiator, 
interpreter, circuit simulator, and compiler?

Most of the material is mixed in the [excercises][sicp-2]
so don't skip them!

But, this is not just a programming book.
It belongs in this list because it teaches the fundamental concepts of computation.
See the section [data as programs][sicp-3] for an example.

[sicp-1]: https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book.html)
[sicp-2]: https://github.com/justinmeiners/excercises/tree/master/sicp
[sicp-3]: https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-26.html#%_sec_4.1.5
[sicp-4]: https://en.wikipedia.org/wiki/Gerald_Jay_Sussman
[sicp-5]: https://en.wikipedia.org/wiki/Hal_Abelson

### Logical Foundations of Mathematics and Computational Complexity

By: [Pavel Pudlak][f1]

![logical foundations of math](logical_foundations.jpg)

This book is a massive and dense survey of topics including
formal systems, set theory, abstract algebra, computability theory, 
analysis of algorithms, and quantum computing. 
The first chapter covered almost everything I had learned about 
algebra and meta-mathematics in my entire undergraduate degree!

Pudlak does a fantastic job of balancing technical
information with philosophical discussion.
I can't recommend this book enough.

Reading this book definitely requires some mathematical maturity.
The author does his best to explains every concept in the book
but it would be hard for me to read about a "group" for the first time
and really understand what he means.

If you read through the other books, and have technical knowledge
you should be well prepared.

[f1]: http://users.math.cas.cz/~pudlak/ 
 ]]></description>
</item>
<item>
<pubDate>Fri, 22 Feb 2019 15:56:57 -0700</pubDate>
<title>The Skills Poor Programmers Lack</title>
<guid isPermaLink="true">https://justinmeiners.github.io/the-skills-programmers-lack/</guid>
<description><![CDATA[ 
 The Skills Poor Programmers Lack
--------------------------------
**02/22/2019**

A friend and I had a discussion about the basic skills that are often lacking in experienced programmers. How can a programmer work for ten or twenty years and never learn to write good code? So often they need close supervision to ensure they go down the right path, and they can never be trusted to take technical leadership on larger tasks. It seems they are just good enough to get by in their job, but they never become *effective*. 

We thought about our experiences and came up with three fundamental skills that we find are most often missing. Note that these are not skills which take a considerable amount of talent or unique insight. Nor are they "trends" or "frameworks" to help you get a new job. They are basic fundamentals which are prerequisites to being a successful programmer.

## Understand how the language works

Programmers cannot write good code unless they understand what they are typing. At the most basic level, this means they need to understand the rules of their programming language well. It is obvious when a programmer doesn't because they solve problems in indirect ways and litter the code with unnecessary statements that they are clueless as to what they actually do. Their mental model of the program does not match with the actual behavior of the code.

You may have seen code which misunderstands how expressions work:

```
if isDelivered and isNotified:
    isDone = True
else:
    isDone = false;
```

Instead of:

```
isDone = isDelivered and isNotified
```

(There may be some cases where the previous style is preferred. It is just an illustration.)

In JavaScript, this is often indicated by `new Promise` inside a `.then()`. In C++, it is attaching `virtual` to every method and destructor and creating every object with `new`. 

Debugging is also extremely difficult if you don't understand the language. You may add a line of code because it fixes a bug for reasons you don't understand. Bugs are mysteries that seem to appear organically, like dust on the shelves. The code seems to have a mind of its own.

Understand the code you write. Know what every line does and why you put it there.

Once you understand the language well, you also need to understand what is going on *inside* the actual computer. Do you know how typing text on a screen makes things happen in the real world? Do you know how the call stack works? Do you know what is on the stack and heap? Do you know how assembly language works? Do you know how the code gets to assembly? Do you know how a closure captures variables? Do you know how the garbage collector works?

Ignorance here most often results in sluggish code that is wasteful of system resources. A classic example is using a `map<string, map<string, ...>>` in C++ (a dictionary of dictionaries). Did you really intend to make a self-balancing tree of self-balancing trees? Choosing a reasonable algorithm or data structure is not premature optimization, it is just picking a good tool for the job.

Of course, no one person can understand *everything* that goes on in modern computers. I don’t know how  [cache coherence](https://en.wikipedia.org/wiki/Cache_coherence) or [instruction reordering](https://preshing.com/20120625/memory-ordering-at-compile-time/) algorithms work. However, there is a certain level everyone *should* know, and every bit beyond that only helps. The minimal level is probably covered by a CS course on [data structures](http://opendatastructures.org/ods-python/) and a course on [assembly and architecture](http://inst.eecs.berkeley.edu/~cs61c/sp15/).

A muddy understanding of how things work is typical of beginners, but it is all too often a problem with experienced programmers if they are not curious and do not take time to learn how things work beyond their immediate job’s needs.

## Anticipate problems

To write reliable code, you must be able to anticipate problems, not just patch individual use cases. I am shocked by the number of times I see code that puts the program in a broken state when a very likely error happens. 

I recently reviewed some code that made an HTTP request to notify a server of a state change in which the programmer assumed the HTTP request would always succeed. If it failed, (and we know how often HTTP requests fail), the record was put into an invalid state. The questions they should have asked when writing this code are: What happens if this fails? Is there another opportunity to send the notification? When is the correct time to record the state change? Careful programmers think through the possible states and transitions of their program.

Using `sleep()`, cron jobs, or `setTimeout` is almost always wrong because it typically means you are waiting for a task to finish and don’t know how long it will take. What if it takes longer than you expect? What if the scheduler gives resources to another program? Will that break your program? It may take a little bit of effort to rig a proper event, but it is always worth it. 

Another common mistake I see is generating a random file or identifier and hoping that collisions will never happen. It is reasonable for an unlikely event to cause an error, but it is not ok if that puts your program in an unusable state. For example, if a successful login generates a session token and it collides with another token, you could reject the login and have the user try again. It is a freak accident that slightly inconveniences the user. On the other hand, what if you generate storage files with random names and you have a collision? You just lost someone’s data! “This probably won’t happen” is not a strategy for writing reliable code.

Unit testing can’t solve this problem either. It can help you stop and think about some inputs to write a test, but more than likely, the cases that you write tests are the ones you anticipated when you wrote the code! Unit testing cannot transform fragile code into reliable code.

Fragile code often results when you lack the experience to know what kinds of things can go wrong, but it can also be the result of a long career of maintaining existing codebases. When working on a large existing system, you typically fix individual bugs and aren’t rewarded by your bosses for improving the system as a whole. You learn that programming is a never-ending patch. Increasing the `sleep()` time may fix the bug today, but never solve the underlying issue. 

## Organize and design systems

Even when armed with the other two skills, it's hard to be effective unless you can organize code into a system that makes sense. I believe OOP and relational database get a lot of flack because programmers tend to be bad at design, not because they are broken paradigms. You simply can't create rigid classes, schemas, and hierarchies without thinking them through. Design itself is too broad a topic to explore in this article (read [Fred Brooks](https://en.wikipedia.org/wiki/Fred_Brooks)), so I want to focus on a few specific attributes that well-designed software tends to have.

Naive programmers think that design means ["don't make functions or classes too long"](http://number-none.com/blow/blog/programming/2014/09/26/carmack-on-inlined-code.html). However, the real problem is writing code that mixes unrelated ideas. Poorly designed software lacks conceptual integrity. Its concepts and division of responsibilities are not well defined. It usually looks like a giant Rube Goldberg machine that haphazardly sets state and triggers events.

Accordingly, good software is built from well-defined concepts with clear responsibilities. Mathematicians and [philosophers][3] spend a lot of time discussing definitions because a good definition allows them to capture and understand some truth about the world. Programmers should think similarly and spend a comparable amount of effort grappling with ideas before writing code.

Good programmers ask questions like:

- "What is this function's purpose?"
- "What does this data structure represent?"
- "Does this function actually represent two separate tasks?"
- "What is the responsibility of this portion of code? What shouldn't it 'know about'?" 
- "What is necessary to be in the public interface?"

Luckily the field is ripe with strategies to help you design code. [Design patterns](https://www.oodesign.com) and [SOLID](https://en.wikipedia.org/wiki/SOLID) can give you guidelines for designing classes. Functional programming encourages writing pure functions (input -> output and no side effects) and maintaining as little state as possible. [Model view controller](https://developer.apple.com/library/archive/documentation/General/Conceptual/DevPedia-CocoaCore/MVC.html) aims to separate UI and storage concerns from program logic. On the other hand, React components form conceptual units by combining the HTML, CSS, and JS into a single component. Unix rejects categories and says [everything is a file](https://en.wikipedia.org/wiki/Everything_is_a_file). All of these seemingly contradictory ideas are valid. The important thing is that the concepts make sense and map closely to the problem you are solving.

Software that is well-designed is also software that is easy to change. Of course, it's too much to ask it to satisfy requirements that contradict its original intent. But, it should accommodate changes that are natural evolutions. A common mistake I see is solving a problem for a few cases, instead of N cases. (If you have a variable called `button3` think again.) Another is treating everything as a special case using `switch` statements instead of using polymorphism.

I think the best way to learn about design is to write and study a lot of programs. Programmers who work only on old programs never learn to write new ones. The studying part is key too. Programmers who only work on small temporary projects (like an agency) may get by without ever improving how to design programs. Good design comes gradually with experience, but only if you think about it and try to improve.

There are no tricks or rules that you can follow to guarantee you will write good software. As Alex Stepanov said, "think, and then the code will be good."

[3]: https://en.wikipedia.org/wiki/Categories_(Aristotle) 
 ]]></description>
</item>
<item>
<pubDate>Sun, 13 Jan 2019 15:56:57 -0700</pubDate>
<title>McCulloch & Pitts Neural Net Simulator</title>
<guid isPermaLink="true">https://justinmeiners.github.io/neural-nets-sim/</guid>
</item>
</channel>
</rss>
